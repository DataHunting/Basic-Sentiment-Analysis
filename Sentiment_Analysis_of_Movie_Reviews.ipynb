{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Sentiment Analysis On Movie Reviews\n",
    "\n",
    "`nltk` is the most popular Python package for Natural Language Processing, it provides algorithms for importing, cleaning, pre-processing text data in human language and then apply computational linguistics algorithms like sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis 1**\n",
    "\n",
    "This program uses the movie_reviews dataset from nltk's corpus, consisting of 2000 reviews marked as positive and negative. A bag-of-words is created for 2000 most common words that occur over the vocabulary of the entire corpus. And each review is represented by a hot-coded feature vector of those 2000 words. A basic sentiment analysis is carried out with nltk's built-in Naive Bayes estimator with a 80-20% split between training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy= 0.864375\n",
      "test accuracy= 0.8025\n",
      "Most Informative Features\n",
      "             outstanding = True              pos : neg    =     10.9 : 1.0\n",
      "                  seagal = True              neg : pos    =      7.6 : 1.0\n",
      "                   mulan = True              pos : neg    =      7.2 : 1.0\n",
      "                   damon = True              pos : neg    =      6.3 : 1.0\n",
      "                   awful = True              neg : pos    =      6.1 : 1.0\n",
      "             wonderfully = True              pos : neg    =      5.8 : 1.0\n",
      "                  poorly = True              neg : pos    =      5.8 : 1.0\n",
      "               laughable = True              neg : pos    =      5.4 : 1.0\n",
      "              ridiculous = True              neg : pos    =      5.3 : 1.0\n",
      "                    lame = True              neg : pos    =      5.3 : 1.0\n",
      "                 unfunny = True              neg : pos    =      5.2 : 1.0\n",
      "                  wasted = True              neg : pos    =      5.1 : 1.0\n",
      "                   waste = True              neg : pos    =      5.0 : 1.0\n",
      "                   worst = True              neg : pos    =      4.9 : 1.0\n",
      "                  stupid = True              neg : pos    =      4.5 : 1.0\n",
      "                  ripley = True              pos : neg    =      4.5 : 1.0\n",
      "             masterpiece = True              pos : neg    =      4.4 : 1.0\n",
      "                    jedi = True              pos : neg    =      4.3 : 1.0\n",
      "               fantastic = True              pos : neg    =      4.3 : 1.0\n",
      "                     era = True              pos : neg    =      4.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews as reviews\n",
    "import random\n",
    "import string\n",
    "\n",
    "# Helper function to create one-hot feature vectors\n",
    "def review_features(doc):\n",
    "    docSet = set(doc)\n",
    "    features = {}\n",
    "    \n",
    "    for word in topKeys:\n",
    "        features[word] = (word in docSet)\n",
    "        \n",
    "    return features\n",
    "\n",
    "# Helper function for stopword removal\n",
    "def build_bag_of_words_features_filtered(words):\n",
    "    return {\n",
    "        word:1 for word in words \\\n",
    "        if not word in useless_words}\n",
    "\n",
    "# Helper function for stemming\n",
    "def stem_with_porter(words):\n",
    "    porter = nltk.PorterStemmer()\n",
    "    new_words = [porter.stem(w) for w in words]\n",
    "    return new_words\n",
    "\n",
    "# Load the reviews dataset\n",
    "docs = [(list(reviews.words(id)), cat) for cat in reviews.categories() for id in reviews.fileids(cat)]\n",
    "random.shuffle(docs)\n",
    "\n",
    "# Create a Bag-of-Words\n",
    "stopWords = nltk.corpus.stopwords.words(\"english\") + list(string.punctuation) + ['--', '---']\n",
    "filtered_words = [word for word in reviews.words() if not word in stopWords]\n",
    "#stemmed_words = stem_with_porter(filtered_words)\n",
    "fd = nltk.FreqDist(word.lower() for word in filtered_words)\n",
    "topKeys = [ key for (key, value) in fd.most_common(2000)]\n",
    "\n",
    "data = [(review_features(doc), label) for (doc, label) in docs]\n",
    "\n",
    "dataCount = len(data)\n",
    "trainCount = int(0.8*dataCount)\n",
    "\n",
    "trainData = data[:trainCount]\n",
    "testData = data[trainCount:]\n",
    "bayes = nltk.NaiveBayesClassifier.train(trainData)\n",
    "\n",
    "print('train accuracy=', nltk.classify.accuracy(bayes, trainData))\n",
    "print('test accuracy=', nltk.classify.accuracy(bayes, testData))\n",
    "\n",
    "bayes.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis 2**\n",
    "\n",
    "This program uses the same dataset. However, each review here is represented by a bag-of-words of 200 most common words occuring in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy= 99.75\n",
      "test accuracy= 78.0\n",
      "Most Informative Features\n",
      "                   damon = 1                 pos : neg    =     12.3 : 1.0\n",
      "             outstanding = 1                 pos : neg    =     10.6 : 1.0\n",
      "                  seagal = 1                 neg : pos    =     10.3 : 1.0\n",
      "              undercover = 1                 neg : pos    =      9.7 : 1.0\n",
      "              schumacher = 1                 neg : pos    =      9.7 : 1.0\n",
      "               stretched = 1                 neg : pos    =      9.0 : 1.0\n",
      "                    lame = 1                 neg : pos    =      8.6 : 1.0\n",
      "                downhill = 1                 neg : pos    =      8.3 : 1.0\n",
      "                 chuckle = 1                 neg : pos    =      8.3 : 1.0\n",
      "                instinct = 1                 neg : pos    =      8.3 : 1.0\n",
      "             wonderfully = 1                 pos : neg    =      8.1 : 1.0\n",
      "               uplifting = 1                 pos : neg    =      7.7 : 1.0\n",
      "              capitalize = 1                 neg : pos    =      7.7 : 1.0\n",
      "                  unique = 1                 pos : neg    =      7.7 : 1.0\n",
      "               thrilling = 1                 pos : neg    =      7.7 : 1.0\n",
      "                lifeless = 1                 neg : pos    =      7.7 : 1.0\n",
      "                  darker = 1                 pos : neg    =      7.7 : 1.0\n",
      "                terrific = 1                 pos : neg    =      7.4 : 1.0\n",
      "                 divorce = 1                 pos : neg    =      7.0 : 1.0\n",
      "              insightful = 1                 pos : neg    =      7.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews as reviews\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "import string\n",
    "\n",
    "# Helper function to create Bag-of-Words Feature vectors\n",
    "def build_bag_of_words_features_filtered(words):\n",
    "    fd = nltk.FreqDist(word.lower() for word in words)\n",
    "    topWords = [ key for (key, value) in fd.most_common(200)]\n",
    "    return {\n",
    "        word:1 for word in topWords \\\n",
    "        if not word in stopWords}\n",
    "\n",
    "stopWords = nltk.corpus.stopwords.words(\"english\") + list(string.punctuation)\n",
    "\n",
    "negative_fileids = reviews.fileids('neg')\n",
    "positive_fileids = reviews.fileids('pos')\n",
    "\n",
    "negative_features = [\n",
    "    (build_bag_of_words_features_filtered(reviews.words(fileids=[f])), 'neg') \\\n",
    "    for f in negative_fileids\n",
    "]\n",
    "\n",
    "positive_features = [\n",
    "    (build_bag_of_words_features_filtered(reviews.words(fileids=[f])), 'pos') \\\n",
    "    for f in positive_fileids\n",
    "]\n",
    "\n",
    "\n",
    "split = 800\n",
    "sentiment_classifier = NaiveBayesClassifier.train(positive_features[:split]+negative_features[:split])\n",
    "train_accuracy = nltk.classify.util.accuracy(sentiment_classifier, positive_features[:split]+negative_features[:split])*100\n",
    "test_accuracy = nltk.classify.util.accuracy(sentiment_classifier, positive_features[split:]+negative_features[split:])*100\n",
    "\n",
    "\n",
    "print('train accuracy=', train_accuracy)\n",
    "print('test accuracy=', test_accuracy)\n",
    "\n",
    "sentiment_classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
